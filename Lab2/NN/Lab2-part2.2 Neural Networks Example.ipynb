{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Lab3-part2 Neural Networks Example.ipynb","provenance":[{"file_id":"11w8y221x00tbZbeEnFIAU88N3FfQtvN_","timestamp":1615486607348}],"collapsed_sections":["JS3vH7RgpEZy"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"sAI8gIO4RBBC"},"source":["# IS 784 Neural Network Example"]},{"cell_type":"markdown","metadata":{"id":"ap84W3FeRBBO"},"source":["In last tutorial we covered basics of Pytorch and neural networks. In this tutorial we combine our previous knowledge and create a basic neural network that will perform sentiment analysis on IMDB dataset.\n"," \n","Please note that  in this tutorial we will use legacy version of the torchtext."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oQNN8CFoRBBP","executionInfo":{"status":"ok","timestamp":1615489413624,"user_tz":-180,"elapsed":1498,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"9637d278-8558-4c15-9dc1-b99af654cc87"},"source":["import torch\n","print(torch.__version__) #version of the pytorh\n","import torch.nn.functional as F\n","import torchtext.legacy as torchtext"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.8.0+cu101\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZRW0mcRQn_PK"},"source":["## Finding Max Length \n"]},{"cell_type":"markdown","metadata":{"id":"9juFZANBZEqX"},"source":["We first need to find the max length of the text in the dataset because our input size is constant. This is because, in MLP models, the linear layer requires fixed-sized input. In More complex models (like RNN), we don't need this part because they can take variable input sizes."]},{"cell_type":"code","metadata":{"id":"D9Ni6oXTich-"},"source":["TEXT = torchtext.data.Field(tokenize='spacy', batch_first=True) # preprocessing parameters can be used to add aditional  preprocessing steps\n","LABEL = torchtext.data.LabelField(dtype = torch.float)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PEQVuI_m3uV"},"source":["train_data, test_data = torchtext.datasets.IMDB.splits(TEXT, LABEL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ac25bdxVXecP","executionInfo":{"status":"ok","timestamp":1615489542591,"user_tz":-180,"elapsed":47845,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"be226a71-ea17-45b0-c925-6f790ab48813"},"source":["max_size=0  \n","count=0\n","sum= 0\n","for i in  range(len(train_data)):\n","  if max_size < len(train_data[i].text):\n","    max_size =len(train_data[i].text)\n","    print(max_size)\n","  count +=1\n","  sum +=len(train_data[0].text)\n","print(\"avarage: \", sum/count)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["259\n","295\n","943\n","964\n","986\n","2789\n","avarage:  259.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UG7I6kZ7oHKX"},"source":["## Training Embeddings"]},{"cell_type":"markdown","metadata":{"id":"Gy6YWYP4oN58"},"source":["Now that we found the max length corpus. Let's create our train and test datasets."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_wJl9cwmuR0","executionInfo":{"status":"ok","timestamp":1615489613947,"user_tz":-180,"elapsed":117834,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"4744b6dd-6508-4cc4-e3b8-77d45dfc180e"},"source":["TEXT = torchtext.data.Field(tokenize='spacy', batch_first=True,fix_length= 2789) # preprocessing paraneters can be used to add aditional  preprocessing steps\n","LABEL = torchtext.data.LabelField(dtype = torch.float)\n","train_data, test_data = torchtext.datasets.IMDB.splits(TEXT, LABEL)\n","print(\"train length is: \",len(train_data))\n","print(\"test length is: \",len(test_data))\n","print(vars(train_data[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train length is:  25000\n","test length is:  25000\n","{'text': ['Anyone', 'new', 'to', 'the', 'incredibly', 'prolific', 'Takashi', 'Miike', \"'s\", 'work', 'might', 'want', 'to', 'think', 'twice', 'about', 'making', 'this', 'startling', 'film', 'their', 'first', 'experience', 'of', 'this', 'truly', 'maverick', 'director', '.', 'In', 'keeping', 'with', 'Miike', \"'s\", 'working', 'practice', 'of', 'taking', 'any', 'work', 'that', 'comes', 'his', 'way', 'and', 'then', 'grafting', 'his', 'own', 'sensibilities', 'onto', 'the', 'script', ',', 'this', 'is', 'at', 'heart', 'a', 'fairly', 'basic', 'yakuza', 'thriller', ',', 'with', 'a', 'morally', 'ambiguous', 'cop', 'chasing', 'a', 'gang', 'which', 'his', 'lawyer', 'brother', 'has', 'fallen', 'in', 'with', '.', 'What', 'takes', 'the', 'movie', 'out', 'of', 'the', 'realms', 'of', 'the', 'same', '-', 'old', 'same', '-', 'old', 'however', ',', 'is', 'the', 'utterly', 'unflinching', 'attitude', 'so', 'some', 'of', 'the', 'most', 'sudden', 'and', 'horrific', 'violence', 'seen', 'in', 'today', \"'s\", 'cinema', '.', 'And', 'this', 'is', \"n't\", 'that', 'nice', 'cool', ',', 'clean', 'violence', 'so', 'beloved', 'of', 'US', 'cinema', '-', 'this', 'stuff', 'is', 'nasty', ',', 'painful', 'and', 'HURTS', '!', 'That', 'said', ',', 'the', 'pace', 'is', 'breakneck', ',', 'the', 'characters', 'are', 'unusual', 'without', 'being', 'just', 'being', 'burdened', 'with', 'stock', 'eccentricities', ',', 'Miike', \"'s\", 'sense', 'of', 'humour', 'reveals', 'itself', 'and', 'the', 'most', 'unexpected', 'moments', ',', 'and', 'his', 'camera', 'is', 'never', 'quite', 'where', 'you', 'expect', 'it', 'to', 'be', ',', 'making', 'it', 'hard', 'to', 'look', 'away', 'from', 'the', 'screen', ',', 'whatever', 'he', 'might', 'be', 'showing', 'you', '!', 'It', 'does', \"n't\", 'have', 'the', '\"', 'Ohmigod', '\"', 'ending', 'of', '\"', 'Dead', 'Or', 'Alive', ',', '\"', 'but', 'if', 'you', \"'re\", 'not', 'squeamish', ',', 'now', \"'s\", 'the', 'time', 'to', 'get', 'on', 'board', 'the', 'Miike', 'bandwagon', 'before', 'he', 'ends', 'up', 'on', 'some', 'Hollywood', 'studio', \"'s\", '\"', 'new', 'John', 'Woo', '\"', 'shopping', 'list', '...'], 'label': 'pos'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MahJWe5rj1xo"},"source":["IMDB library contains more than 100000 words. Using all of the words will make our computation slower and removing them will reduce our networks efficiency slightly. Words we removed will be  marked with `<unk>` token. We can use  `max_size`  or `min_freq` parameters of  `build_vocab` function to limit size of our vocabulary.   "]},{"cell_type":"code","metadata":{"id":"mb1Bthmaj1Lr"},"source":["TEXT.build_vocab(train_data,\n","                 max_size = 30000)\n","LABEL.build_vocab(train_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LOLkG_dgjxH4","executionInfo":{"status":"ok","timestamp":1615489615813,"user_tz":-180,"elapsed":117637,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"498cbaff-07ee-48da-8441-a9856d9bc3d7"},"source":["print(\"Unique tokens in TEXT vocabulary:\",len(TEXT.vocab))\n","print(\"Unique tokens in LABEL vocabulary:\",len(LABEL.vocab))\n","print(TEXT.vocab.freqs.most_common(20))\n","print(LABEL.vocab.freqs)\n","print(TEXT.unk_token)\n","print(TEXT.pad_token)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Unique tokens in TEXT vocabulary: 23402\n","Unique tokens in LABEL vocabulary: 2\n","[('the', 289838), (',', 275296), ('.', 236843), ('and', 156483), ('a', 156282), ('of', 144055), ('to', 133886), ('is', 109095), ('in', 87676), ('I', 77546), ('it', 76545), ('that', 70355), ('\"', 63329), (\"'s\", 61928), ('this', 60483), ('-', 52863), ('/><br', 50935), ('was', 50013), ('as', 43508), ('with', 42807)]\n","Counter({'pos': 12500, 'neg': 12500})\n","<unk>\n","<pad>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z9PiSpoDmuy-"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n","    (train_data, test_data), batch_size=32, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_13hT7vnf6h","executionInfo":{"status":"ok","timestamp":1615488487139,"user_tz":-180,"elapsed":11399,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"2dbb145c-3dfd-4e57-d6a1-988f685fdac5"},"source":["for batch in train_iterator:\n","  print(batch)\n","  break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","[torchtext.legacy.data.batch.Batch of size 32 from IMDB]\n","\t[.text]:[torch.cuda.LongTensor of size 32x2789 (GPU 0)]\n","\t[.label]:[torch.cuda.FloatTensor of size 32 (GPU 0)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMq70YQQ2Q-o","executionInfo":{"status":"ok","timestamp":1615243248503,"user_tz":-180,"elapsed":70733,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"668c3a85-3d7d-4bb9-be9a-25c6718ec366"},"source":["print(TEXT.vocab.itos[3000]) # itos -> int to string  | stoi -> str to int\n","print(TEXT.vocab.itos[3001])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cell\n","disbelief\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-lyBQqtx30rl"},"source":["Before creating our network, we need to solve how we could convert our words to a format that our network will understood clearly. Although `torchtext` converted our words to numerical form, due to sequential nature of the numbers this will create semantic errors. For example, 3000th word  ‘cell’ and 3001th word  ‘disbelief’ although they have no semantic connections between them they follow each other in our vocabulary.   \n","\n","Our second option is  converting our vocabulary to one-hot vectors. Although this option is a good alternative in small vocabularies, in our example we need to create vector with  30000 parameters. Combined with 2789-word count in our sentences (with padding),  we will have  60 million bits of input. \n","\n","Our most feasible option is creating word vectors. Essentially, we will create a lookup table that will convert our words into vector with predetermined size. For this purpose, pytorch contains [nn.Embeddings](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) module. This module which creates a lookup table with trainable weights. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"TRCXsKl5-u3e"},"source":["Lets create our network;"]},{"cell_type":"code","metadata":{"id":"xBCxdM6joBbZ"},"source":["class Network(torch.nn.Module):\n","    def __init__(self,pad_idx):\n","        super().__init__()\n","        self.embedding = torch.nn.Embedding(num_embeddings = 30002, embedding_dim =100,padding_idx = pad_idx)\n","        self.layer1 = torch.nn.Linear(2789*100, 1000)\n","        self.layer2 = torch.nn.Linear(1000, 1)\n","\n","\n","    def forward(self, x):\n","        x = self.embedding(x).view(x.size(0),-1)\n","        x = self.layer1(x)\n","        x = F.relu(x)\n","        x = self.layer2(x)\n","        return x       "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ENDe2sd5rJn4","executionInfo":{"status":"ok","timestamp":1615488540121,"user_tz":-180,"elapsed":2436,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"597e1fc2-e39c-4b4f-a019-a46b10863dbe"},"source":["model = Network(pad_idx = TEXT.vocab.stoi[TEXT.pad_token])\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Network(\n","  (embedding): Embedding(30002, 100, padding_idx=1)\n","  (layer1): Linear(in_features=278900, out_features=1000, bias=True)\n","  (layer2): Linear(in_features=1000, out_features=1, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N_yLoKZ6OZHp"},"source":["We will use Adam optimizer and BCEWithLogitsLoss function for due to its better performance when there is single class.   \n","\n","Please note that BCEWithLogitsLoss function combines a sigmoid layer and the BCELoss (Binary Cross Entropy)  in one single class while giving more stable results while using them separately. We also need to apply sigmoid function to output of our network if we want to obtain results separately."]},{"cell_type":"code","metadata":{"id":"W5B5TDLdqi93"},"source":["loss_fn = torch.nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(params= model.parameters(),lr= 0.0005) #default lr is 0.001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6v0Fw71NqNgD"},"source":["model = model.to(device)\n","loss_fn = loss_fn.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uJUAGG5EDYJo"},"source":["Now that we are ready lets train our network;"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IVmtOVeVQJoM","executionInfo":{"status":"ok","timestamp":1615488801187,"user_tz":-180,"elapsed":225647,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"af095702-9102-419b-9515-8615aac06c4f"},"source":["import time\n","# Training loop\n","N_EPOCHS = 2\n","\n","tr_loss = []\n","model.train()\n","\n","for epoch in range(N_EPOCHS):\n","    \n","    # Calculate training time\n","    start_time = time.time()\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    \n","    batch_no = 0\n","    for batch in train_iterator:\n","        \n","        # Reset the gradient to not use them in multiple passes \n","        optimizer.zero_grad()\n","        \n","        predictions = model(batch.text).squeeze(1)\n","        loss = loss_fn(predictions, batch.label.squeeze(0))\n","\n","        # Backprop\n","        loss.backward()\n","        \n","        # Optimize the weights\n","        optimizer.step()\n","        \n","        # Record accuracy and loss\n","        epoch_loss += loss.item()\n","        \n","        correct = (torch.round(torch.sigmoid(predictions)) == batch.label.squeeze(0)).float() \n","        acc = correct.sum() / len(correct)\n","        epoch_acc +=acc.item()\n","\n","        batch_no = batch_no +1\n","        \n","        if batch_no%60 == 0:\n","          print(f'Epoch:  {epoch+1:2} | Batch No: {batch_no} | Loss: {loss.item():.3f} | Accuracy: {acc.item()*100:.2f}%')\n","\n","    \n","    train_loss = epoch_loss / len(train_iterator)\n","\n","    end_time = time.time()\n","\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    \n","    print('\\n')    \n","    print(f'Epoch: {epoch+1:2} | Epoch Time: {elapsed_mins}m {elapsed_secs}s')\n","    print(f'\\tAvarage Train Loss: {train_loss:.3f} ')\n","    print('\\n') "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch:   1 | Batch No: 60 | Loss: 0.732 | Accuracy: 40.62%\n","Epoch:   1 | Batch No: 120 | Loss: 0.656 | Accuracy: 59.38%\n","Epoch:   1 | Batch No: 180 | Loss: 0.716 | Accuracy: 56.25%\n","Epoch:   1 | Batch No: 240 | Loss: 0.714 | Accuracy: 53.12%\n","Epoch:   1 | Batch No: 300 | Loss: 0.674 | Accuracy: 59.38%\n","Epoch:   1 | Batch No: 360 | Loss: 0.737 | Accuracy: 43.75%\n","Epoch:   1 | Batch No: 420 | Loss: 0.762 | Accuracy: 40.62%\n","Epoch:   1 | Batch No: 480 | Loss: 0.654 | Accuracy: 59.38%\n","Epoch:   1 | Batch No: 540 | Loss: 0.616 | Accuracy: 68.75%\n","Epoch:   1 | Batch No: 600 | Loss: 0.609 | Accuracy: 65.62%\n","Epoch:   1 | Batch No: 660 | Loss: 0.571 | Accuracy: 62.50%\n","Epoch:   1 | Batch No: 720 | Loss: 0.554 | Accuracy: 62.50%\n","Epoch:   1 | Batch No: 780 | Loss: 0.657 | Accuracy: 59.38%\n","\n","\n","Epoch:  1 | Epoch Time: 1m 52s\n","\tAvarage Train Loss: 0.669 \n","\n","\n","Epoch:   2 | Batch No: 60 | Loss: 0.109 | Accuracy: 96.88%\n","Epoch:   2 | Batch No: 120 | Loss: 0.110 | Accuracy: 96.88%\n","Epoch:   2 | Batch No: 180 | Loss: 0.209 | Accuracy: 90.62%\n","Epoch:   2 | Batch No: 240 | Loss: 0.160 | Accuracy: 93.75%\n","Epoch:   2 | Batch No: 300 | Loss: 0.121 | Accuracy: 96.88%\n","Epoch:   2 | Batch No: 360 | Loss: 0.137 | Accuracy: 93.75%\n","Epoch:   2 | Batch No: 420 | Loss: 0.196 | Accuracy: 96.88%\n","Epoch:   2 | Batch No: 480 | Loss: 0.180 | Accuracy: 87.50%\n","Epoch:   2 | Batch No: 540 | Loss: 0.199 | Accuracy: 87.50%\n","Epoch:   2 | Batch No: 600 | Loss: 0.101 | Accuracy: 96.88%\n","Epoch:   2 | Batch No: 660 | Loss: 0.203 | Accuracy: 90.62%\n","Epoch:   2 | Batch No: 720 | Loss: 0.153 | Accuracy: 93.75%\n","Epoch:   2 | Batch No: 780 | Loss: 0.170 | Accuracy: 93.75%\n","\n","\n","Epoch:  2 | Epoch Time: 1m 52s\n","\tAvarage Train Loss: 0.149 \n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uQb1CXQ1GGAt"},"source":["Now that our training is complete, we can test our network using our test_iterator. During testing we do not need to calculate gradients so we can use `torch.no_grad()` module to prevent backpropagation. Similarly, `.eval()` function of turn our network  to evaluation mode. On the other hand,  `.train()` function can be used to re enable training mode."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hCdD1EBy4W8V","executionInfo":{"status":"ok","timestamp":1615245281024,"user_tz":-180,"elapsed":14556,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"25ad9d29-30c2-4e17-b108-796f8e26ccfe"},"source":["test_epoch_loss = 0\n","test_epoch_acc = 0\n","\n","# Turm on evalutaion mode\n","model.eval()\n","\n","# No need to backprop in eval\n","with torch.no_grad():\n","\n","    for batch in test_iterator:\n","\n","        test_predictions = model(batch.text).squeeze(1)\n","        \n","        test_loss = loss_fn(test_predictions, batch.label)\n","\n","        test_epoch_loss += test_loss.item()\n","        \n","        correct = (torch.round(torch.sigmoid(test_predictions)) == batch.label.squeeze(0)).float() \n","        acc = correct.sum() / len(correct)\n","        \n","        test_epoch_acc +=acc.item()\n","\n","test_loss = test_epoch_loss/len(test_iterator)\n","test_acc = test_epoch_acc  / len(test_iterator)\n","print(f'Test Loss: {test_loss:.3f} | | Test Acc: {test_acc*100:.2f}%')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test Loss: 0.759 | | Test Acc: 64.39%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"__UbHBkVGLTX"},"source":["Finally let’s see our networks effectiveness on actual examples."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YpCc6SC-ajWc","executionInfo":{"status":"ok","timestamp":1615245321518,"user_tz":-180,"elapsed":1049,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"2854273c-5069-41d4-a6dc-5c2b54639389"},"source":["review1 = 'This is the best movie I have ever watched!'\n","review2 = 'This is an okay movie'\n","review3 = 'This was a waste of time! I hated this movie.'\n","\n","import spacy\n","nlp = spacy.load('en')\n","\n","model.eval()\n","tokenized = [tok.text for tok in nlp.tokenizer(review1)]\n","if len(tokenized) < 2789:\n","    tokenized += ['<pad>'] * (2789 - len(tokenized))\n","\n","# Map words to word embeddings\n","indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n","tensor = torch.LongTensor(indexed).to(device)\n","tensor = tensor.unsqueeze(0)\n","# Get predicitons\n","prediction = torch.sigmoid(model(tensor))\n","\n","print(prediction.item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.9385111927986145\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JS3vH7RgpEZy"},"source":["## Using Pretrained Embeddings"]},{"cell_type":"markdown","metadata":{"id":"PcNBTuyUJs5a"},"source":[" In previous example we trained our word embeddings from scratch. In this example we will use pretrained embeddings instead of training them. These embeddings can provide better network accuracy because they are trained on large datasets and they provide semantic meanings for the words.\n"]},{"cell_type":"code","metadata":{"id":"O2VrcAYBpNT0"},"source":["TEXT2 = torchtext.data.Field(tokenize='spacy', batch_first=True,fix_length= 2789)  # fix_length \n","LABEL2 = torchtext.data.LabelField(dtype = torch.float)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o39W3XZ9pNT1"},"source":["train_data2, test_data2 = torchtext.datasets.IMDB.splits(TEXT2, LABEL2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dlk9VQZbOJqW"},"source":["Torchtext’s vocabulary module provides easy access to  popular word embeddings. In this example we will use Glove word vectors which is trained on Wikipedia and Gigaword 5 datasets. This embedding contains trained on six billion tokens and  400-thousand-word vocabulary. It has different sized word vector from 50 dimension to 300. Glove will be discussed upcoming word embedding lecture in detailly.    \n","This process can take some time because Colab needs to download word embeddings from  torchtext repository. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t33VM4lWpNT1","executionInfo":{"status":"ok","timestamp":1615246551558,"user_tz":-180,"elapsed":70542,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"1d44fa82-1e17-4828-e102-8742b9b274ce"},"source":["TEXT2.build_vocab(train_data2,\n","                 max_size = 30000,\n","                  vectors = \"glove.6B.100d\", \n","                 # Set unknown vectors\n","                  unk_init = torch.Tensor.normal_)\n","LABEL2.build_vocab(train_data2)\n","print(\"Unique tokens in TEXT vocabulary:\",len(TEXT2.vocab))\n","print(\"Unique tokens in LABEL vocabulary:\",len(LABEL2.vocab))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Unique tokens in TEXT vocabulary: 30002\n","Unique tokens in LABEL vocabulary: 2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a3EExTTSQNcW"},"source":["Now that our vocabulary is ready we can create  iterators and  network."]},{"cell_type":"code","metadata":{"id":"bbCPQkG0pNT2"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator2, test_iterator2 = torchtext.data.BucketIterator.splits(\n","    (train_data2, test_data2), batch_size=64, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hBwnicRpNT3","executionInfo":{"status":"ok","timestamp":1615246570615,"user_tz":-180,"elapsed":2570,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"04aec611-6580-42cc-f365-8f1b18e60860"},"source":["model2 = Network(pad_idx = TEXT2.vocab.stoi[TEXT2.pad_token])\n","print(model2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Network(\n","  (embedding): Embedding(30002, 100, padding_idx=1)\n","  (layer1): Linear(in_features=278900, out_features=1000, bias=True)\n","  (layer2): Linear(in_features=1000, out_features=1, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dUCE6uiuRC4e"},"source":["We need to load our word embedding to our network and set unknown  and padding tokens to zero. After that we have a choice, we can either freeze embedding layer to prevent further training or we can continue to train the embeddings to fine tune the weights.  "]},{"cell_type":"code","metadata":{"id":"QOfbGb81pNT4"},"source":["model2.embedding.weight.data.copy_(TEXT2.vocab.vectors)\n","model2.embedding.weight.data[TEXT2.vocab.stoi[TEXT2.unk_token]] = torch.zeros(100)\n","model2.embedding.weight.data[TEXT2.vocab.stoi[TEXT2.pad_token]] = torch.zeros(100)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CDGW98EfSSgo"},"source":["Lets continue with our training and test steps."]},{"cell_type":"code","metadata":{"id":"8a6ZN4LCx2gt"},"source":["model2.embedding.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a8yGUrmWpNT4"},"source":["We will use Adam optimizer and BCEWithLogitsLoss function for due to its better performance when there is single class."]},{"cell_type":"code","metadata":{"id":"4fZhrqKnpNT4"},"source":["loss_fn2 = torch.nn.BCEWithLogitsLoss()\n","optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.0005)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"osRVrPS_pNT4"},"source":["model2 = model2.to(device)\n","loss_fn2 = loss_fn2.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5epQ8MWepNT4","executionInfo":{"status":"ok","timestamp":1615246711385,"user_tz":-180,"elapsed":128290,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"75984f7e-0aaf-415a-c451-3eeee2ec44a9"},"source":["import time\n","# Training loop\n","N_EPOCHS = 2\n","\n","tr_loss2 = []\n","model2.train()\n","\n","for epoch in range(N_EPOCHS):\n","    \n","    # Calculate training time\n","    start_time = time.time()\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    batch_no = 0\n","\n","    \n","    for batch in train_iterator2:\n","        \n","        # Reset the gradient to not use them in multiple passes \n","        optimizer2.zero_grad()\n","        \n","        predictions = model2(batch.text).squeeze(1)\n","        loss = loss_fn2(predictions, batch.label.squeeze(0))\n","        \n","        # Backprop\n","        loss.backward()\n","        \n","        # Optimize the weights\n","        optimizer2.step()\n","        \n","        # Record accuracy and loss\n","        epoch_loss += loss.item()\n","\n","        correct = (torch.round(torch.sigmoid(predictions)) == batch.label.squeeze(0)).float() \n","        acc = correct.sum() / len(correct)\n","        epoch_acc +=acc.item()\n","\n","        batch_no = batch_no +1\n","        \n","        if batch_no%60 == 0:\n","          print(f'Epoch:  {epoch+1:2} | Batch No: {batch_no} | Loss: {loss.item():.3f} | Accuracy: {acc.item()*100:.2f}%')\n","    \n","    train_loss = epoch_loss / len(train_iterator2)\n","        \n","    \n","    end_time = time.time()\n","\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    \n","    # Save training metrics\n","    tr_loss2.append(train_loss)\n","        \n","    print(f'Epoch: {epoch+1:2} | Epoch Time: {elapsed_mins}m {elapsed_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} ')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch:   1 | Batch No: 60 | Loss: 0.743 | Accuracy: 57.81%\n","Epoch:   1 | Batch No: 120 | Loss: 0.641 | Accuracy: 64.06%\n","Epoch:   1 | Batch No: 180 | Loss: 0.606 | Accuracy: 60.94%\n","Epoch:   1 | Batch No: 240 | Loss: 0.582 | Accuracy: 75.00%\n","Epoch:   1 | Batch No: 300 | Loss: 0.565 | Accuracy: 68.75%\n","Epoch:   1 | Batch No: 360 | Loss: 0.531 | Accuracy: 75.00%\n","Epoch:  1 | Epoch Time: 1m 4s\n","\tTrain Loss: 0.613 \n","Epoch:   2 | Batch No: 60 | Loss: 0.230 | Accuracy: 90.62%\n","Epoch:   2 | Batch No: 120 | Loss: 0.212 | Accuracy: 89.06%\n","Epoch:   2 | Batch No: 180 | Loss: 0.263 | Accuracy: 92.19%\n","Epoch:   2 | Batch No: 240 | Loss: 0.297 | Accuracy: 87.50%\n","Epoch:   2 | Batch No: 300 | Loss: 0.216 | Accuracy: 93.75%\n","Epoch:   2 | Batch No: 360 | Loss: 0.230 | Accuracy: 92.19%\n","Epoch:  2 | Epoch Time: 1m 3s\n","\tTrain Loss: 0.282 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jx2Xd-_t_1qP","executionInfo":{"status":"ok","timestamp":1615246730265,"user_tz":-180,"elapsed":13824,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"cf95a137-a813-4148-89ae-c6a679e57515"},"source":["test_epoch_loss = 0\n","test_epoch_acc = 0\n","\n","# Turm off dropout while evaluating\n","model2.eval()\n","\n","# No need to backprop in eval\n","with torch.no_grad():\n","\n","    for batch in test_iterator2:\n","\n","        test_predictions = model2(batch.text).squeeze(1)\n","        \n","        test_loss = loss_fn2(test_predictions, batch.label)\n","\n","        test_epoch_loss += test_loss.item()\n","        \n","        correct = (torch.round(torch.sigmoid(test_predictions)) == batch.label.squeeze(0)).float() \n","        acc = correct.sum() / len(correct)\n","        \n","        test_epoch_acc +=acc.item()\n","\n","test_loss = test_epoch_loss/len(test_iterator2)\n","test_acc = test_epoch_acc  / len(test_iterator2)\n","print(f'Test Loss: {test_loss:.3f} | | Test Acc: {test_acc*100:.2f}%')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test Loss: 0.491 | | Test Acc: 79.06%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bX-UiuVBTUDi"},"source":["As we can see while using pretrained embeddings we obtained better accuracy from our network with pretrained embeddings. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YOWh6DUs_1qa","executionInfo":{"status":"ok","timestamp":1615246742948,"user_tz":-180,"elapsed":1086,"user":{"displayName":"arif ozan","photoUrl":"https://lh3.googleusercontent.com/-VeZXYcDd6_A/AAAAAAAAAAI/AAAAAAAAAuY/oDVdzSjg-m4/s64/photo.jpg","userId":"12465436653524186566"}},"outputId":"3fa412ff-4cca-4ff6-ca88-d7fec1359912"},"source":["review1 = 'This is the best movie I have ever watched!'\n","review2 = 'This is an okay movie'\n","review3 = 'This was a waste of time! I hated this movie.'\n","\n","\n","import spacy\n","nlp = spacy.load('en')\n","\n","model2.eval()\n","tokenized = [tok.text for tok in nlp.tokenizer(review1)]\n","if len(tokenized) < 2789:\n","    tokenized += ['<pad>'] * (2789 - len(tokenized))\n","\n","# Map words to word embeddings\n","indexed = [TEXT2.vocab.stoi[t] for t in tokenized]\n","tensor = torch.LongTensor(indexed).to(device)\n","tensor = tensor.unsqueeze(0)\n","# Get predicitons\n","prediction = torch.sigmoid(model2(tensor))\n","\n","print(prediction.item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.7838658690452576\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1N6HkskFUj78"},"source":["## Recommended Readings"]},{"cell_type":"markdown","metadata":{"id":"qLk4T9KWUqjL"},"source":["*   For more information about networks, optimizers and data utilities , you can refer to [pytorch learn the basics tutorial]( https://pytorch.org/tutorials/beginner/basics/intro.html)\n","\n","\n"]}]}